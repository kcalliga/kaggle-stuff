{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45044159",
   "metadata": {},
   "source": [
    "# Ordinal Regression Template – Ordered Categories\n",
    "\n",
    "This template is for **ordinal regression** problems, where labels are discrete but **ordered**:\n",
    "\n",
    "- Star ratings (1–5)  \n",
    "- Draft grades (mapped A,B,C,D → 3,2,1,0)  \n",
    "- Severity levels (none, mild, moderate, severe)  \n",
    "\n",
    "We cover:\n",
    "\n",
    "1. Treating ordinal as numeric (regression)  \n",
    "2. Treating ordinal as multiclass classification  \n",
    "3. Simple cumulative ordinal model using multiple logistic regressions  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2df1a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 1. Imports & Config (Ordinal Regression) ==========\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Optional, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, f1_score, accuracy_score, classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.base import clone\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "plt.rcParams[\"figure.dpi\"] = 100\n",
    "\n",
    "# ---- Config ----\n",
    "DATA_DIR = Path(\"../input\")\n",
    "TRAIN_FILE = \"ordinal_data.csv\"\n",
    "\n",
    "TARGET_COL = \"rating\"  # ordered categories like 1..5\n",
    "ID_COL = \"id\"          # optional\n",
    "\n",
    "RANDOM_STATE = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb40b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 2. Load Data & Feature Types ==========\n",
    "\n",
    "def load_data(data_dir: Path = DATA_DIR, train_file: str = TRAIN_FILE) -> pd.DataFrame:\n",
    "    path = data_dir / train_file\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Train file not found: {path}\")\n",
    "    df = pd.read_csv(path)\n",
    "    print(\"Data shape:\", df.shape)\n",
    "    display(df.head())\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_numeric_features(df: pd.DataFrame, exclude: Optional[List[str]] = None) -> List[str]:\n",
    "    cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    if exclude:\n",
    "        cols = [c for c in cols if c not in exclude]\n",
    "    return cols\n",
    "\n",
    "\n",
    "def get_categorical_features(df: pd.DataFrame) -> List[str]:\n",
    "    return df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "\n",
    "df = load_data()\n",
    "print(\"Target distribution:\")\n",
    "display(df[TARGET_COL].value_counts().sort_index())\n",
    "\n",
    "exclude_cols = [TARGET_COL]\n",
    "if ID_COL in df.columns:\n",
    "    exclude_cols.append(ID_COL)\n",
    "\n",
    "num_cols = get_numeric_features(df, exclude=exclude_cols)\n",
    "cat_cols = get_categorical_features(df)\n",
    "\n",
    "print(\"Numeric cols:\", num_cols[:10], \"...\" if len(num_cols) > 10 else \"\")\n",
    "print(\"Categorical cols:\", cat_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc83b0fe",
   "metadata": {},
   "source": [
    "### 3️⃣ Preprocessing Pipeline\n",
    "\n",
    "Standard tabular preprocessing:\n",
    "\n",
    "- Median imputation for numeric  \n",
    "- Most-frequent imputation for categoricals  \n",
    "- Scaling numeric features  \n",
    "- One-hot encoding categoricals  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21fd92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_imputer = SimpleImputer(strategy=\"median\")\n",
    "categorical_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "\n",
    "numeric_pipeline = Pipeline([\n",
    "    (\"imputer\", numeric_imputer),\n",
    "    (\"scaler\", StandardScaler(with_mean=False)),\n",
    "])\n",
    "categorical_pipeline = Pipeline([\n",
    "    (\"imputer\", categorical_imputer),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "])\n",
    "\n",
    "transformers = []\n",
    "if num_cols:\n",
    "    transformers.append((\"num\", numeric_pipeline, num_cols))\n",
    "if cat_cols:\n",
    "    transformers.append((\"cat\", categorical_pipeline, cat_cols))\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=transformers, remainder=\"drop\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95beb840",
   "metadata": {},
   "source": [
    "### 4️⃣ Baseline 1 – Treat Ordinal as Numeric Regression\n",
    "\n",
    "Map the ordered labels to integers and use regression, then round back to nearest class.\n",
    "\n",
    "Pros: very simple.  \n",
    "Cons: ignores discrete nature and may over/under-penalize big vs small errors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca7546e",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = [TARGET_COL]\n",
    "if ID_COL in df.columns:\n",
    "    drop_cols.append(ID_COL)\n",
    "\n",
    "X = df.drop(columns=drop_cols)\n",
    "y = df[TARGET_COL].astype(int)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "reg_pipe = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", LinearRegression()),\n",
    "])\n",
    "\n",
    "reg_pipe.fit(X_train, y_train)\n",
    "y_pred_reg = reg_pipe.predict(X_valid)\n",
    "\n",
    "unique_classes = np.sort(y.unique())\n",
    "y_pred_reg_rounded = np.clip(np.rint(y_pred_reg), unique_classes.min(), unique_classes.max()).astype(int)\n",
    "\n",
    "rmse = mean_squared_error(y_valid, y_pred_reg, squared=False)\n",
    "f1w = f1_score(y_valid, y_pred_reg_rounded, average=\"weighted\")\n",
    "acc = accuracy_score(y_valid, y_pred_reg_rounded)\n",
    "print(\"Regression baseline on ordinal:\")\n",
    "print(f\"RMSE (continuous): {rmse:.4f}\")\n",
    "print(f\"Accuracy (rounded): {acc:.4f}, F1-weighted (rounded): {f1w:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec39407",
   "metadata": {},
   "source": [
    "### 5️⃣ Baseline 2 – Treat Ordinal as Multiclass Classification\n",
    "\n",
    "Ignore ordering and train a standard multiclass classifier.\n",
    "\n",
    "Pros: uses standard classification tooling.  \n",
    "Cons: does not exploit ordering structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd3a897",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_pipe = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=None,\n",
    "        n_jobs=-1,\n",
    "        random_state=RANDOM_STATE,\n",
    "    )),\n",
    "])\n",
    "\n",
    "clf_pipe.fit(X_train, y_train)\n",
    "y_pred_clf = clf_pipe.predict(X_valid)\n",
    "\n",
    "acc_clf = accuracy_score(y_valid, y_pred_clf)\n",
    "f1w_clf = f1_score(y_valid, y_pred_clf, average=\"weighted\")\n",
    "print(\"Multiclass classification treating ordinal as nominal:\")\n",
    "print(f\"Accuracy: {acc_clf:.4f}, F1-weighted: {f1w_clf:.4f}\")\n",
    "print(classification_report(y_valid, y_pred_clf, digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfe2c7b",
   "metadata": {},
   "source": [
    "### 6️⃣ Simple Cumulative Ordinal Model\n",
    "\n",
    "We create K-1 binary problems for ordered classes 1..K:\n",
    "\n",
    "- For each threshold c (except last), model `P(y > c | x)` via logistic regression.  \n",
    "- Recover class probabilities from cumulative probabilities.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7444e147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_ordinal_cumulative(X_train_t, y_train, X_valid_t, base_clf, classes):\n",
    "    classes = np.sort(classes)\n",
    "    n_classes = len(classes)\n",
    "    models = []\n",
    "    proba_gt = []\n",
    "\n",
    "    for c in classes[:-1]:\n",
    "        y_bin = (y_train > c).astype(int)\n",
    "        clf = clone(base_clf)\n",
    "        clf.fit(X_train_t, y_bin)\n",
    "        p = clf.predict_proba(X_valid_t)[:, 1]\n",
    "        proba_gt.append(p)\n",
    "        models.append(clf)\n",
    "\n",
    "    proba_gt = np.vstack(proba_gt)\n",
    "\n",
    "    n_samples = X_valid_t.shape[0]\n",
    "    class_probs = np.zeros((n_samples, n_classes))\n",
    "\n",
    "    class_probs[:, 0] = 1 - proba_gt[0, :]\n",
    "    for i in range(1, n_classes - 1):\n",
    "        class_probs[:, i] = proba_gt[i - 1, :] - proba_gt[i, :]\n",
    "    class_probs[:, -1] = proba_gt[-1, :]\n",
    "\n",
    "    class_probs = np.clip(class_probs, 1e-6, 1.0)\n",
    "    class_probs = class_probs / class_probs.sum(axis=1, keepdims=True)\n",
    "\n",
    "    pred_indices = np.argmax(class_probs, axis=1)\n",
    "    y_pred_ord = classes[pred_indices]\n",
    "\n",
    "    return y_pred_ord, class_probs\n",
    "\n",
    "\n",
    "logit = LogisticRegression(max_iter=2000, n_jobs=-1)\n",
    "X_train_t = preprocessor.fit_transform(X_train)\n",
    "X_valid_t = preprocessor.transform(X_valid)\n",
    "\n",
    "y_pred_ord, class_probs = fit_ordinal_cumulative(\n",
    "    X_train_t, y_train, X_valid_t, logit, unique_classes\n",
    ")\n",
    "\n",
    "acc_ord = accuracy_score(y_valid, y_pred_ord)\n",
    "f1w_ord = f1_score(y_valid, y_pred_ord, average=\"weighted\")\n",
    "print(\"Ordinal cumulative logit:\")\n",
    "print(f\"Accuracy: {acc_ord:.4f}, F1-weighted: {f1w_ord:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026bfe03",
   "metadata": {},
   "source": [
    "### 7️⃣ Decision Guide\n",
    "\n",
    "- Use **regression baseline** when labels are many and almost continuous.  \n",
    "- Use **multiclass classification** when ordering is less critical.  \n",
    "- Use **ordinal cumulative model** when ordering is important and you care about \"distance\" between categories.\n",
    "\n",
    "You can feed ordinal probabilities or scores into downstream models.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
