{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f8f37cb",
   "metadata": {},
   "source": [
    "# Time-Series Template – Forecasting with Tabular + Temporal Structure\n",
    "\n",
    "This notebook is a template for **time-series problems**, especially where data is in **tabular form with a time column**, optionally multiple entities (e.g. `store_id`, `symbol`, `sensor_id`).\n",
    "\n",
    "It focuses on:\n",
    "\n",
    "- Avoiding **leakage** with time-based splits\n",
    "- Creating **lag** and **rolling window** features\n",
    "- Handling **per-entity vs global** models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14a34a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 1. Imports & Config (Time-Series) ==========\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Optional, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "plt.rcParams[\"figure.dpi\"] = 100\n",
    "\n",
    "# ---- Config ----\n",
    "DATA_DIR = Path(\"../input\")\n",
    "TRAIN_FILE = \"train.csv\"\n",
    "TEST_FILE = \"test.csv\"   # optional\n",
    "\n",
    "TIME_COL = \"date\"        # name of time column\n",
    "TARGET_COL = \"target\"    # name of numeric target\n",
    "ID_COL = None            # e.g. \"store_id\" or \"series_id\", or None for single series\n",
    "\n",
    "RANDOM_STATE = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb34b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 2. Load, Sort & Basic EDA ==========\n",
    "\n",
    "def load_data(\n",
    "    data_dir: Path = DATA_DIR,\n",
    "    train_file: str = TRAIN_FILE,\n",
    "    test_file: Optional[str] = TEST_FILE,\n",
    "):\n",
    "    train_path = data_dir / train_file\n",
    "    if not train_path.exists():\n",
    "        raise FileNotFoundError(f\"Train file not found: {train_path}\")\n",
    "    train_df = pd.read_csv(train_path)\n",
    "\n",
    "    test_df = None\n",
    "    if test_file is not None:\n",
    "        test_path = data_dir / test_file\n",
    "        if test_path.exists():\n",
    "            test_df = pd.read_csv(test_path)\n",
    "        else:\n",
    "            print(f\"Test file not found: {test_path} (continuing without test_df)\")\n",
    "\n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "train_df, test_df = load_data()\n",
    "\n",
    "# Ensure time column is datetime\n",
    "train_df[TIME_COL] = pd.to_datetime(train_df[TIME_COL], errors=\"coerce\")\n",
    "if test_df is not None and TIME_COL in test_df.columns:\n",
    "    test_df[TIME_COL] = pd.to_datetime(test_df[TIME_COL], errors=\"coerce\")\n",
    "\n",
    "# Sort by time (and ID if provided)\n",
    "if ID_COL is not None and ID_COL in train_df.columns:\n",
    "    train_df = train_df.sort_values([ID_COL, TIME_COL]).reset_index(drop=True)\n",
    "else:\n",
    "    train_df = train_df.sort_values(TIME_COL).reset_index(drop=True)\n",
    "\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "display(train_df.head())\n",
    "\n",
    "# Simple target over time plot (single series or sample of entities)\n",
    "if ID_COL is None:\n",
    "    plt.plot(train_df[TIME_COL], train_df[TARGET_COL])\n",
    "    plt.title(\"Target over time\")\n",
    "    plt.xlabel(TIME_COL)\n",
    "    plt.ylabel(TARGET_COL)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f94ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_datetime_parts(df: pd.DataFrame, time_col: str = TIME_COL) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df[time_col] = pd.to_datetime(df[time_col], errors=\"coerce\")\n",
    "    df[f\"{time_col}_year\"] = df[time_col].dt.year\n",
    "    df[f\"{time_col}_month\"] = df[time_col].dt.month\n",
    "    df[f\"{time_col}_day\"] = df[time_col].dt.day\n",
    "    df[f\"{time_col}_dow\"] = df[time_col].dt.dayofweek\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_lag_features(\n",
    "    df: pd.DataFrame,\n",
    "    target_col: str = TARGET_COL,\n",
    "    lags: List[int] = [1, 7, 14],\n",
    "    group_col: Optional[str] = ID_COL,\n",
    ") -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    if group_col is not None and group_col in df.columns:\n",
    "        df = df.sort_values([group_col, TIME_COL])\n",
    "        for lag in lags:\n",
    "            df[f\"{target_col}_lag{lag}\"] = df.groupby(group_col)[target_col].shift(lag)\n",
    "    else:\n",
    "        df = df.sort_values(TIME_COL)\n",
    "        for lag in lags:\n",
    "            df[f\"{target_col}_lag{lag}\"] = df[target_col].shift(lag)\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_rolling_features(\n",
    "    df: pd.DataFrame,\n",
    "    target_col: str = TARGET_COL,\n",
    "    windows: List[int] = [7, 28],\n",
    "    group_col: Optional[str] = ID_COL,\n",
    ") -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    if group_col is not None and group_col in df.columns:\n",
    "        df = df.sort_values([group_col, TIME_COL])\n",
    "        for w in windows:\n",
    "            df[f\"{target_col}_rollmean_{w}\"] = (\n",
    "                df.groupby(group_col)[target_col].shift(1).rolling(window=w).mean()\n",
    "            )\n",
    "            df[f\"{target_col}_rollstd_{w}\"] = (\n",
    "                df.groupby(group_col)[target_col].shift(1).rolling(window=w).std()\n",
    "            )\n",
    "    else:\n",
    "        df = df.sort_values(TIME_COL)\n",
    "        for w in windows:\n",
    "            df[f\"{target_col}_rollmean_{w}\"] = df[target_col].shift(1).rolling(window=w).mean()\n",
    "            df[f\"{target_col}_rollstd_{w}\"] = df[target_col].shift(1).rolling(window=w).std()\n",
    "    return df\n",
    "\n",
    "\n",
    "# Apply basic FE\n",
    "ts_fe = add_datetime_parts(train_df, TIME_COL)\n",
    "ts_fe = add_lag_features(ts_fe, TARGET_COL, lags=[1, 7, 14], group_col=ID_COL)\n",
    "ts_fe = add_rolling_features(ts_fe, TARGET_COL, windows=[7, 28], group_col=ID_COL)\n",
    "\n",
    "print(\"After TS feature engineering:\", ts_fe.shape)\n",
    "display(ts_fe.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faae09f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_based_split(\n",
    "    df: pd.DataFrame,\n",
    "    time_col: str = TIME_COL,\n",
    "    valid_fraction: float = 0.2,\n",
    "):\n",
    "    df = df.sort_values(time_col)\n",
    "    n = len(df)\n",
    "    split_idx = int((1 - valid_fraction) * n)\n",
    "    train_df = df.iloc[:split_idx].copy()\n",
    "    valid_df = df.iloc[split_idx:].copy()\n",
    "    return train_df, valid_df\n",
    "\n",
    "\n",
    "# Drop rows where lag/rolling features are NaN (at the beginning of series)\n",
    "ts_fe_clean = ts_fe.dropna().reset_index(drop=True)\n",
    "train_ts, valid_ts = time_based_split(ts_fe_clean, TIME_COL, valid_fraction=0.2)\n",
    "\n",
    "print(\"Train TS shape:\", train_ts.shape)\n",
    "print(\"Valid TS shape:\", valid_ts.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04366922",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_imputer = SimpleImputer(strategy=\"median\")\n",
    "categorical_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "\n",
    "def get_feature_target(df: pd.DataFrame, target_col: str = TARGET_COL):\n",
    "    drop_cols = [target_col, TIME_COL]\n",
    "    if ID_COL is not None and ID_COL in df.columns:\n",
    "        drop_cols.append(ID_COL)\n",
    "    X = df.drop(columns=drop_cols)\n",
    "    y = df[target_col]\n",
    "    return X, y\n",
    "\n",
    "\n",
    "X_train_ts, y_train_ts = get_feature_target(train_ts)\n",
    "X_valid_ts, y_valid_ts = get_feature_target(valid_ts)\n",
    "\n",
    "num_cols = X_train_ts.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = X_train_ts.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "numeric_pipeline = Pipeline([\n",
    "    (\"imputer\", numeric_imputer),\n",
    "    (\"scaler\", StandardScaler(with_mean=False)),\n",
    "])\n",
    "cat_pipeline = Pipeline([\n",
    "    (\"imputer\", categorical_imputer),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "])\n",
    "\n",
    "transformers = []\n",
    "if num_cols:\n",
    "    transformers.append((\"num\", numeric_pipeline, num_cols))\n",
    "if cat_cols:\n",
    "    transformers.append((\"cat\", cat_pipeline, cat_cols))\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=transformers, remainder=\"drop\")\n",
    "\n",
    "rf_ts = RandomForestRegressor(\n",
    "    n_estimators=300,\n",
    "    max_depth=None,\n",
    "    n_jobs=-1,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "ts_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", rf_ts),\n",
    "])\n",
    "\n",
    "ts_pipeline.fit(X_train_ts, y_train_ts)\n",
    "y_pred_ts = ts_pipeline.predict(X_valid_ts)\n",
    "\n",
    "rmse = mean_squared_error(y_valid_ts, y_pred_ts, squared=False)\n",
    "mae = mean_absolute_error(y_valid_ts, y_pred_ts)\n",
    "\n",
    "print(f\"Time-series RF baseline – RMSE: {rmse:.4f}, MAE: {mae:.4f}\")\n",
    "\n",
    "plt.plot(valid_ts[TIME_COL], y_valid_ts, label=\"Actual\")\n",
    "plt.plot(valid_ts[TIME_COL], y_pred_ts, label=\"Predicted\")\n",
    "plt.legend()\n",
    "plt.title(\"Forecast vs Actual (Validation)\")\n",
    "plt.xlabel(TIME_COL)\n",
    "plt.ylabel(TARGET_COL)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
