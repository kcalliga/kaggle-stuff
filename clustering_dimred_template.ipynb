{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bede761",
   "metadata": {},
   "source": [
    "# Unsupervised Template ‚Äì Clustering & Dimensionality Reduction\n",
    "\n",
    "This notebook is a reusable template for **unsupervised tabular problems**, focused on:\n",
    "\n",
    "- **Clustering** (KMeans, hierarchical, DBSCAN)\n",
    "- **Dimensionality Reduction** (PCA, optional t-SNE/UMAP)\n",
    "- Understanding structure **without labels**\n",
    "\n",
    "You can copy this notebook into any project where you want to:\n",
    "- Discover natural groups (segments, player archetypes, customer cohorts)\n",
    "- Visualize high-dimensional data in 2D\n",
    "- Build features for downstream supervised models.\n",
    "\n",
    "---\n",
    "\n",
    "## üîÅ High-Level Workflow (Unsupervised)\n",
    "\n",
    "1. **Imports & config**\n",
    "2. **Load data**\n",
    "3. **Column typing & selection of features for unsupervised work**\n",
    "4. **Basic EDA (without target)**\n",
    "5. **Scaling & Dimensionality Reduction**\n",
    "   - PCA (core)\n",
    "   - t-SNE / UMAP (optional, slower but nicer visually)\n",
    "6. **Clustering**\n",
    "   - KMeans (baseline)\n",
    "   - Optional: hierarchical / DBSCAN\n",
    "7. **Cluster Evaluation & Interpretation**\n",
    "   - Elbow / silhouette\n",
    "   - Cluster profiles (feature means per cluster)\n",
    "8. **Save cluster assignments & embeddings** for downstream use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edfa78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 1. Imports & Config (Unsupervised: Clustering + DimRed) ==========\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Optional, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "plt.rcParams[\"figure.dpi\"] = 100\n",
    "\n",
    "# ---- Config (edit per dataset) ----\n",
    "DATA_DIR = Path(\"../input\")\n",
    "DATA_FILE = \"data.csv\"       # change to your dataset\n",
    "ID_COL = \"id\"                # optional, set to None if not applicable\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Which columns to use for unsupervised analysis\n",
    "# - You can leave as None to auto-detect numeric columns\n",
    "UNSUPERVISED_FEATURES: Optional[List[str]] = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c5adfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 2. Load Data & Helper Functions ==========\n",
    "\n",
    "def load_data(data_dir: Path = DATA_DIR, data_file: str = DATA_FILE) -> pd.DataFrame:\n",
    "    path = data_dir / data_file\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Data file not found: {path}\")\n",
    "    df = pd.read_csv(path)\n",
    "    print(\"Data shape:\", df.shape)\n",
    "    display(df.head())\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_numeric_features(df: pd.DataFrame, exclude: Optional[List[str]] = None) -> List[str]:\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    if exclude:\n",
    "        num_cols = [c for c in num_cols if c not in exclude]\n",
    "    return num_cols\n",
    "\n",
    "\n",
    "def summarize_dataframe(df: pd.DataFrame, name: str = \"df\"):\n",
    "    print(f\"===== {name} summary =====\")\n",
    "    print(\"Shape:\", df.shape)\n",
    "    display(df.head())\n",
    "    print(\"\\nDtypes:\")\n",
    "    display(df.dtypes)\n",
    "    print(\"\\nMissing (%):\")\n",
    "    display((df.isna().mean() * 100).sort_values(ascending=False))\n",
    "\n",
    "\n",
    "df = load_data()\n",
    "summarize_dataframe(df, \"df\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e358b6",
   "metadata": {},
   "source": [
    "### 3Ô∏è‚É£ Choose Features for Unsupervised Analysis\n",
    "\n",
    "For clustering and dimensionality reduction, we usually:\n",
    "\n",
    "- Focus on **numeric features** (or encoded versions of categoricals)\n",
    "- Exclude identifiers (`ID_COL`) and any leakage-like columns (targets, obvious labels)\n",
    "- Optionally, apply some domain-based filtering (e.g., only skill metrics for players)\n",
    "\n",
    "You can either:\n",
    "- Let the notebook auto-pick numeric columns, or\n",
    "- Manually set `UNSUPERVISED_FEATURES` in the config block.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256e707c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which columns to use\n",
    "exclude_cols = []\n",
    "if ID_COL is not None and ID_COL in df.columns:\n",
    "    exclude_cols.append(ID_COL)\n",
    "\n",
    "if UNSUPERVISED_FEATURES is None:\n",
    "    feature_cols = get_numeric_features(df, exclude=exclude_cols)\n",
    "    print(\"Auto-selected numeric features:\", feature_cols)\n",
    "else:\n",
    "    feature_cols = [c for c in UNSUPERVISED_FEATURES if c in df.columns]\n",
    "    print(\"Using configured features:\", feature_cols)\n",
    "\n",
    "X_raw = df[feature_cols].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caa77c1",
   "metadata": {},
   "source": [
    "### 4Ô∏è‚É£ Basic EDA Without Labels\n",
    "\n",
    "Even without a target, we can:\n",
    "\n",
    "- Look at distributions of key features\n",
    "- Check correlations between features\n",
    "- Spot obvious scaling differences (some features 0‚Äì1, others 0‚Äì10,000)\n",
    "\n",
    "This informs scaling decisions and whether PCA is likely to be meaningful.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f96817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms for a sample of features\n",
    "sample_feats = feature_cols[:10]  # adjust or slice more\n",
    "X_raw[sample_feats].hist(bins=30, figsize=(14, 8))\n",
    "plt.suptitle(\"Feature distributions (subset)\", y=1.02)\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap (subset if many features)\n",
    "corr_sample_cols = feature_cols[:20]\n",
    "corr = X_raw[corr_sample_cols].corr()\n",
    "sns.heatmap(corr, cmap=\"coolwarm\", center=0)\n",
    "plt.title(\"Correlation heatmap (subset of features)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3d8561",
   "metadata": {},
   "source": [
    "### 5Ô∏è‚É£ Scaling & PCA (Core Dimensionality Reduction)\n",
    "\n",
    "Most clustering algorithms (especially KMeans) are **distance-based**, so scaling matters.\n",
    "\n",
    "We will:\n",
    "\n",
    "1. Apply **StandardScaler** to numeric features\n",
    "2. Fit **PCA** to capture main variance directions\n",
    "3. Inspect explained variance to choose number of components\n",
    "4. Create a 2D PCA embedding for visualization & clustering\n",
    "\n",
    "You can later replace/augment this with t-SNE/UMAP for nicer visuals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0665a181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_raw)\n",
    "print(\"Scaled shape:\", X_scaled.shape)\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=min(20, X_scaled.shape[1]))\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "explained_var = pca.explained_variance_ratio_\n",
    "print(\"Explained variance ratio (first 10):\", explained_var[:10])\n",
    "print(\"Cumulative explained variance (first 10):\", np.cumsum(explained_var[:10]))\n",
    "\n",
    "plt.plot(np.cumsum(explained_var))\n",
    "plt.xlabel(\"Number of components\")\n",
    "plt.ylabel(\"Cumulative explained variance\")\n",
    "plt.title(\"PCA ‚Äì Cumulative explained variance\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 2D PCA for visualization\n",
    "X_pca2 = X_pca[:, :2]\n",
    "pca_df = pd.DataFrame(X_pca2, columns=[\"PC1\", \"PC2\"])\n",
    "pca_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4e87bd",
   "metadata": {},
   "source": [
    "### (Optional) t-SNE / UMAP for Nonlinear Structure\n",
    "\n",
    "PCA is linear. For more complex manifolds, you can try:\n",
    "\n",
    "- **t-SNE** (good for local structure, small/medium datasets)\n",
    "- **UMAP** (often faster and preserves both local/global structure)\n",
    "\n",
    "Both are mainly for **visualization**, not for modeling directly.\n",
    "\n",
    "Below is an optional t-SNE block (can be slow on large data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2ab87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_TSNE = False  # set to True if you want to run t-SNE (may be slow)\n",
    "\n",
    "tsne_df = None\n",
    "if RUN_TSNE:\n",
    "    tsne = TSNE(\n",
    "        n_components=2,\n",
    "        perplexity=30,\n",
    "        learning_rate=\"auto\",\n",
    "        init=\"pca\",\n",
    "        random_state=RANDOM_STATE,\n",
    "    )\n",
    "    X_tsne = tsne.fit_transform(X_scaled)\n",
    "    tsne_df = pd.DataFrame(X_tsne, columns=[\"TSNE1\", \"TSNE2\"])\n",
    "    plt.scatter(tsne_df[\"TSNE1\"], tsne_df[\"TSNE2\"], s=5, alpha=0.7)\n",
    "    plt.title(\"t-SNE embedding (no clusters yet)\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2f4ca1",
   "metadata": {},
   "source": [
    "### 6Ô∏è‚É£ KMeans Clustering on PCA Embedding\n",
    "\n",
    "We start with **KMeans** as a baseline clustering algorithm.\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. Choose a range for `k` (number of clusters)\n",
    "2. Fit KMeans for each `k` on PCA-reduced data\n",
    "3. Inspect:\n",
    "   - Inertia (elbow method)\n",
    "   - Silhouette score (cluster separation)\n",
    "4. Pick a reasonable `k` and refit\n",
    "\n",
    "We cluster on the 2D or higher-dimensional PCA space (e.g., first 10 PCs) instead of raw features to reduce noise and speed up clustering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccea3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll cluster on the first N PCA components (not just 2D)\n",
    "N_PCS_FOR_CLUSTERING = min(10, X_pca.shape[1])\n",
    "X_pca_for_clustering = X_pca[:, :N_PCS_FOR_CLUSTERING]\n",
    "\n",
    "k_range = range(2, 11)\n",
    "inertias = []\n",
    "sil_scores = []\n",
    "\n",
    "for k in k_range:\n",
    "    km = KMeans(n_clusters=k, random_state=RANDOM_STATE, n_init=\"auto\")\n",
    "    labels = km.fit_predict(X_pca_for_clustering)\n",
    "    inertias.append(km.inertia_)\n",
    "    sil = silhouette_score(X_pca_for_clustering, labels)\n",
    "    sil_scores.append(sil)\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.plot(list(k_range), inertias, marker=\"o\")\n",
    "ax1.set_xlabel(\"k (number of clusters)\")\n",
    "ax1.set_ylabel(\"Inertia\", color=\"tab:blue\")\n",
    "ax1.tick_params(axis=\"y\", labelcolor=\"tab:blue\")\n",
    "ax1.set_title(\"KMeans: Inertia & Silhouette vs k\")\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(list(k_range), sil_scores, marker=\"s\", color=\"tab:red\")\n",
    "ax2.set_ylabel(\"Silhouette score\", color=\"tab:red\")\n",
    "ax2.tick_params(axis=\"y\", labelcolor=\"tab:red\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"k values:\", list(k_range))\n",
    "print(\"Inertias:\", inertias)\n",
    "print(\"Silhouette scores:\", sil_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f524ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose k based on elbow/silhouette (edit this)\n",
    "BEST_K = 4\n",
    "\n",
    "kmeans_final = KMeans(n_clusters=BEST_K, random_state=RANDOM_STATE, n_init=\"auto\")\n",
    "cluster_labels = kmeans_final.fit_predict(X_pca_for_clustering)\n",
    "\n",
    "pca_df[\"cluster\"] = cluster_labels\n",
    "\n",
    "plt.scatter(pca_df[\"PC1\"], pca_df[\"PC2\"], c=pca_df[\"cluster\"], cmap=\"tab10\", s=10, alpha=0.8)\n",
    "plt.title(f\"KMeans clustering (k={BEST_K}) on 2D PCA\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.colorbar(label=\"Cluster\")\n",
    "plt.show()\n",
    "\n",
    "# Attach clusters back to original df\n",
    "df_with_clusters = df.copy()\n",
    "df_with_clusters[\"cluster\"] = cluster_labels\n",
    "display(df_with_clusters.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bdbc62",
   "metadata": {},
   "source": [
    "### 7Ô∏è‚É£ Cluster Profiles & Interpretation\n",
    "\n",
    "To understand what each cluster represents, we:\n",
    "\n",
    "- Compute **mean/median** of each feature per cluster\n",
    "- Look for patterns (e.g., cluster 0 = high value customers, cluster 1 = low activity)\n",
    "- Optionally, visualize distributions per cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbdaa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_summary = df_with_clusters.groupby(\"cluster\")[feature_cols].mean().T\n",
    "display(cluster_summary)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(cluster_summary, cmap=\"coolwarm\", center=0)\n",
    "plt.title(\"Cluster feature means (standard scale)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfa33b3",
   "metadata": {},
   "source": [
    "### (Optional) Other Clustering Methods\n",
    "\n",
    "Once KMeans is working, you can try:\n",
    "\n",
    "- **AgglomerativeClustering** (hierarchical):\n",
    "  - `AgglomerativeClustering(n_clusters=BEST_K, linkage=\"ward\")`\n",
    "- **DBSCAN** for density-based clusters (no need to choose k):\n",
    "  - `DBSCAN(eps=0.5, min_samples=5)`\n",
    "\n",
    "These can capture shapes and densities that KMeans misses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c633accf",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_EXTRA_CLUSTERING = False\n",
    "\n",
    "if RUN_EXTRA_CLUSTERING:\n",
    "    # Hierarchical\n",
    "    agg = AgglomerativeClustering(n_clusters=BEST_K)\n",
    "    labels_agg = agg.fit_predict(X_pca_for_clustering)\n",
    "    plt.scatter(pca_df[\"PC1\"], pca_df[\"PC2\"], c=labels_agg, cmap=\"tab10\", s=10, alpha=0.8)\n",
    "    plt.title(\"Agglomerative clustering on 2D PCA\")\n",
    "    plt.show()\n",
    "\n",
    "    # DBSCAN\n",
    "    db = DBSCAN(eps=0.5, min_samples=10)\n",
    "    labels_db = db.fit_predict(X_pca_for_clustering)\n",
    "    plt.scatter(pca_df[\"PC1\"], pca_df[\"PC2\"], c=labels_db, cmap=\"tab20\", s=10, alpha=0.8)\n",
    "    plt.title(\"DBSCAN clustering on 2D PCA (noise = -1)\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e83ccd0",
   "metadata": {},
   "source": [
    "### 8Ô∏è‚É£ Saving Embeddings & Cluster Assignments\n",
    "\n",
    "You typically want to **reuse**:\n",
    "\n",
    "- `df_with_clusters` (original data + cluster labels) as features in supervised models\n",
    "- `pca_df` (2D embedding) for visualization\n",
    "- `X_pca` (higher-dimensional embedding) as an alternative feature space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dae99f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = Path(\"./unsupervised_outputs\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_with_clusters.to_csv(OUTPUT_DIR / \"data_with_clusters.csv\", index=False)\n",
    "pca_out = pca_df.copy()\n",
    "pca_out.to_csv(OUTPUT_DIR / \"pca_2d_with_clusters.csv\", index=False)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\" - data_with_clusters.csv\")\n",
    "print(\" - pca_2d_with_clusters.csv\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
