{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8eccfe54",
   "metadata": {},
   "source": [
    "# Multi-Target Regression Template – Tabular\n",
    "\n",
    "This notebook is a template for **multi-output regression** problems, where you predict **multiple numeric targets** simultaneously.\n",
    "\n",
    "It is similar to the single-target regression workflow, but uses:\n",
    "\n",
    "- A list of target columns (`TARGET_COLS`)\n",
    "- Multi-output wrappers (`MultiOutputRegressor`)\n",
    "- Per-target and overall metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9b65a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 1. Imports & Config (Multi-Target Regression) ==========\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Optional, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "try:\n",
    "    from xgboost import XGBRegressor\n",
    "except ImportError:\n",
    "    XGBRegressor = None\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "plt.rcParams[\"figure.dpi\"] = 100\n",
    "\n",
    "# ---- Config ----\n",
    "DATA_DIR = Path(\"../input\")\n",
    "TRAIN_FILE = \"train.csv\"\n",
    "TEST_FILE = \"test.csv\"\n",
    "\n",
    "TARGET_COLS = [\"target1\", \"target2\"]  # list of numeric targets\n",
    "ID_COL = \"id\"\n",
    "\n",
    "RANDOM_STATE = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c934c5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 2. Load Data & Helpers ==========\n",
    "\n",
    "def load_data(\n",
    "    data_dir: Path = DATA_DIR,\n",
    "    train_file: str = TRAIN_FILE,\n",
    "    test_file: Optional[str] = TEST_FILE,\n",
    "):\n",
    "    train_path = data_dir / train_file\n",
    "    if not train_path.exists():\n",
    "        raise FileNotFoundError(f\"Train file not found: {train_path}\")\n",
    "    train_df = pd.read_csv(train_path)\n",
    "\n",
    "    test_df = None\n",
    "    if test_file is not None:\n",
    "        test_path = data_dir / test_file\n",
    "        if test_path.exists():\n",
    "            test_df = pd.read_csv(test_path)\n",
    "        else:\n",
    "            print(f\"Test file not found: {test_path} (continuing without test_df)\")\n",
    "    print(\"Train shape:\", train_df.shape)\n",
    "    if test_df is not None:\n",
    "        print(\"Test shape:\", test_df.shape)\n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "def get_numeric_features(df: pd.DataFrame, exclude: Optional[List[str]] = None) -> List[str]:\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    if exclude:\n",
    "        num_cols = [c for c in num_cols if c not in exclude]\n",
    "    return num_cols\n",
    "\n",
    "\n",
    "def get_categorical_features(df: pd.DataFrame) -> List[str]:\n",
    "    return df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "\n",
    "train_df, test_df = load_data()\n",
    "print(\"Targets:\", TARGET_COLS)\n",
    "display(train_df[TARGET_COLS].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f4c9c8",
   "metadata": {},
   "source": [
    "### 3️⃣ Simple Preprocessing & Multi-Output Baseline Models\n",
    "\n",
    "We’ll start with:\n",
    "\n",
    "- Median imputation for numeric features\n",
    "- Most frequent for categoricals\n",
    "- One-hot encoding for categoricals\n",
    "- MultiOutputRegressor wrapper for base models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eadde16",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_imputer = SimpleImputer(strategy=\"median\")\n",
    "categorical_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "\n",
    "def build_preprocessor(df: pd.DataFrame):\n",
    "    num_cols = get_numeric_features(df, exclude=TARGET_COLS + ([ID_COL] if ID_COL in df.columns else []))\n",
    "    cat_cols = get_categorical_features(df)\n",
    "\n",
    "    numeric_pipeline = Pipeline([\n",
    "        (\"imputer\", numeric_imputer),\n",
    "        (\"scaler\", StandardScaler(with_mean=False)),\n",
    "    ])\n",
    "    cat_pipeline = Pipeline([\n",
    "        (\"imputer\", categorical_imputer),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "    ])\n",
    "\n",
    "    transformers = []\n",
    "    if num_cols:\n",
    "        transformers.append((\"num\", numeric_pipeline, num_cols))\n",
    "    if cat_cols:\n",
    "        transformers.append((\"cat\", cat_pipeline, cat_cols))\n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers=transformers, remainder=\"drop\")\n",
    "    return preprocessor\n",
    "\n",
    "\n",
    "def build_multioutput_regressor(base_type: str):\n",
    "    if base_type == \"rf\":\n",
    "        base = RandomForestRegressor(\n",
    "            n_estimators=300,\n",
    "            max_depth=None,\n",
    "            n_jobs=-1,\n",
    "            random_state=RANDOM_STATE,\n",
    "        )\n",
    "    elif base_type == \"elasticnet\":\n",
    "        base = ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=RANDOM_STATE)\n",
    "    elif base_type == \"xgb\":\n",
    "        if XGBRegressor is None:\n",
    "            raise ImportError(\"xgboost not installed\")\n",
    "        base = XGBRegressor(\n",
    "            n_estimators=500,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=6,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            tree_method=\"hist\",\n",
    "            random_state=RANDOM_STATE,\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown base_type: {base_type}\")\n",
    "\n",
    "    return MultiOutputRegressor(base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0aa954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_multioutput_models(\n",
    "    df: pd.DataFrame,\n",
    "    target_cols: List[str] = TARGET_COLS,\n",
    "    id_col: Optional[str] = ID_COL,\n",
    "    base_types: Optional[List[str]] = None,\n",
    "    test_size: float = 0.2,\n",
    "    random_state: int = RANDOM_STATE,\n",
    "):\n",
    "    if base_types is None:\n",
    "        base_types = [\"rf\", \"elasticnet\", \"xgb\"]\n",
    "\n",
    "    df = df.copy()\n",
    "    drop_cols = target_cols.copy()\n",
    "    if id_col is not None and id_col in df.columns:\n",
    "        drop_cols.append(id_col)\n",
    "\n",
    "    X = df.drop(columns=drop_cols)\n",
    "    Y = df[target_cols]\n",
    "\n",
    "    X_train, X_valid, Y_train, Y_valid = train_test_split(\n",
    "        X, Y, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    preprocessor = build_preprocessor(df)\n",
    "    results = []\n",
    "\n",
    "    for b in base_types:\n",
    "        print(f\"\\n=== Base model: {b} ===\")\n",
    "        try:\n",
    "            reg = build_multioutput_regressor(b)\n",
    "            pipe = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", reg)])\n",
    "            pipe.fit(X_train, Y_train)\n",
    "\n",
    "            Y_pred = pipe.predict(X_valid)\n",
    "\n",
    "            # Per-target RMSE and R2\n",
    "            per_target = {}\n",
    "            for i, t in enumerate(target_cols):\n",
    "                rmse_t = mean_squared_error(Y_valid.iloc[:, i], Y_pred[:, i], squared=False)\n",
    "                r2_t = r2_score(Y_valid.iloc[:, i], Y_pred[:, i])\n",
    "                per_target[t] = {\"rmse\": rmse_t, \"r2\": r2_t}\n",
    "                print(f\"  {t}: RMSE={rmse_t:.4f}, R²={r2_t:.4f}\")\n",
    "\n",
    "            # Aggregate RMSE\n",
    "            overall_rmse = mean_squared_error(Y_valid.values, Y_pred, squared=False)\n",
    "            print(f\"Overall RMSE (all targets): {overall_rmse:.4f}\")\n",
    "\n",
    "            results.append({\"base_type\": b, \"overall_rmse\": overall_rmse, \"per_target\": per_target})\n",
    "        except Exception as e:\n",
    "            print(\"Error:\", e)\n",
    "\n",
    "    results_df = pd.DataFrame(\n",
    "        [{\n",
    "            \"base_type\": r[\"base_type\"],\n",
    "            \"overall_rmse\": r[\"overall_rmse\"],\n",
    "        } for r in results]\n",
    "    ).sort_values(\"overall_rmse\")\n",
    "    display(results_df)\n",
    "    return results, results_df\n",
    "\n",
    "\n",
    "multi_results, multi_results_df = evaluate_multioutput_models(train_df)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
