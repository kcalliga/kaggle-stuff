{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cf706c4",
   "metadata": {},
   "source": [
    "# NLP Text Classification Template – TF-IDF → Models\n",
    "\n",
    "This notebook is a template for **text classification** tasks, such as:\n",
    "\n",
    "- Sentiment classification (positive / neutral / negative)  \n",
    "- Topic labels (sports / finance / tech)  \n",
    "- Toxic vs non-toxic comments  \n",
    "\n",
    "It uses classic, robust components:\n",
    "\n",
    "- Text cleaning (light)  \n",
    "- **TF-IDF** features  \n",
    "- Linear models (LogisticRegression) + RF baseline  \n",
    "\n",
    "You can later swap TF-IDF with transformer embeddings, but this is a strong baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8584e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 1. Imports & Config (NLP Text Classification) ==========\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    ")\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "plt.rcParams[\"figure.dpi\"] = 100\n",
    "\n",
    "# ---- Config ----\n",
    "DATA_DIR = Path(\"../input\")\n",
    "TRAIN_FILE = \"train_text.csv\"\n",
    "\n",
    "TEXT_COL = \"text\"\n",
    "TARGET_COL = \"label\"\n",
    "\n",
    "RANDOM_STATE = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce09063a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 2. Load Data ==========\n",
    "\n",
    "def load_data(data_dir: Path = DATA_DIR, train_file: str = TRAIN_FILE) -> pd.DataFrame:\n",
    "    path = data_dir / train_file\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Train file not found: {path}\")\n",
    "    df = pd.read_csv(path)\n",
    "    print(\"Data shape:\", df.shape)\n",
    "    display(df.head())\n",
    "    return df\n",
    "\n",
    "\n",
    "df = load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61689bad",
   "metadata": {},
   "source": [
    "### 3️⃣ Label Distribution & Text Lengths\n",
    "\n",
    "We first look at:\n",
    "\n",
    "- Class balance  \n",
    "- Text length distribution (short vs long texts)  \n",
    "- Potential data issues (empty text, etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faef93d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Label distribution:\")\n",
    "display(df[TARGET_COL].value_counts(dropna=False))\n",
    "display(df[TARGET_COL].value_counts(normalize=True))\n",
    "\n",
    "df[\"text_len\"] = df[TEXT_COL].astype(str).str.len()\n",
    "sns.histplot(df[\"text_len\"], bins=50)\n",
    "plt.title(\"Text length distribution\")\n",
    "plt.xlabel(\"Number of characters\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339631cb",
   "metadata": {},
   "source": [
    "### 4️⃣ Train/Validation Split\n",
    "\n",
    "We do a standard stratified split so each class is represented.  \n",
    "For Kaggle-style setups with separate test data, this is just for local validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061518ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[TEXT_COL].astype(str)\n",
    "y = df[TARGET_COL]\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train size:\", X_train.shape[0])\n",
    "print(\"Valid size:\", X_valid.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b6d13b",
   "metadata": {},
   "source": [
    "### 5️⃣ Text Vectorization with TF-IDF\n",
    "\n",
    "We convert raw text into numeric features using **TF-IDF**.\n",
    "\n",
    "Guidelines:\n",
    "\n",
    "- For short texts: `ngram_range=(1, 2)` is usually good.  \n",
    "- For long texts: limit `max_features` and tune `min_df`.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e376c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(\n",
    "    max_features=50000,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2,\n",
    ")\n",
    "\n",
    "X_train_vec = tfidf.fit_transform(X_train)\n",
    "X_valid_vec = tfidf.transform(X_valid)\n",
    "\n",
    "print(\"Vectorized shapes:\", X_train_vec.shape, X_valid_vec.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464c47f8",
   "metadata": {},
   "source": [
    "### 6️⃣ Baseline Models: Logistic Regression & Random Forest\n",
    "\n",
    "We evaluate:\n",
    "\n",
    "- **LogisticRegression** (very strong baseline for text)  \n",
    "- **RandomForest** (tree-based baseline, often weaker but included for completeness)\n",
    "\n",
    "Metrics:\n",
    "\n",
    "- Accuracy  \n",
    "- F1 (weighted)  \n",
    "- Confusion matrix  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a95fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(clf, name: str):\n",
    "    clf.fit(X_train_vec, y_train)\n",
    "    y_pred = clf.predict(X_valid_vec)\n",
    "    acc = accuracy_score(y_valid, y_pred)\n",
    "    f1 = f1_score(y_valid, y_pred, average=\"weighted\")\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(f\"Accuracy: {acc:.4f} | F1 (weighted): {f1:.4f}\")\n",
    "    print(classification_report(y_valid, y_pred, digits=4))\n",
    "    cm = confusion_matrix(y_valid, y_pred)\n",
    "    ConfusionMatrixDisplay(cm).plot()\n",
    "    plt.title(f\"Confusion Matrix – {name}\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "logreg = LogisticRegression(max_iter=2000, n_jobs=-1)\n",
    "evaluate_model(logreg, \"Logistic Regression\")\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300, max_depth=None, n_jobs=-1, random_state=RANDOM_STATE\n",
    ")\n",
    "evaluate_model(rf, \"Random Forest\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d53d98",
   "metadata": {},
   "source": [
    "### 7️⃣ Next Steps\n",
    "\n",
    "- Tune TF-IDF hyperparameters (`min_df`, `max_features`, `ngram_range`).  \n",
    "- Try other linear models (LinearSVC, SGDClassifier).  \n",
    "- Add class weights if labels are imbalanced.  \n",
    "- Upgrade to transformer embeddings for more advanced performance.\n",
    "\n",
    "You can save the fitted TF-IDF vectorizer and model with joblib/pickle.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
